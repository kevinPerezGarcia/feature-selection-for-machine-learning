```{python}
from pprint import pprint
import sys
sys.path.append('../utils')
```

# Métodos de filtrado básicos

```{python}
from preamble import preamble
X_train, X_test, y_train, y_test = preamble('../data/dataset_1.csv')
```

```{python}
import pandas as pd

X_train.dtypes.unique()
```

```{python}
X_train.nunique()
```

## Variables constantes

### Asumiendo que las características de X son categóricas y numéricas

```{python}
constant_features = [
    feat for feat in X_train.columns if X_train[feat].nunique() == 1
]

print(len(constant_features))
```

### Asumiendo que las características de X son sólo numéricas

```{python}
constant_features = [
    feat for feat in X_train.columns if X_train[feat].std() == 0
]

print(len(constant_features))
```

```{python}
from sklearn.feature_selection import VarianceThreshold

sel = VarianceThreshold(threshold=0).set_output(transform='pandas')
sel.fit(X_train)
X_train = sel.transform(X_train)
X_test = sel.transform(X_test)

print(f'The number of columns in X_train is {X_train.shape[1]}')
print(f'The number of columns in X_test is {X_test.shape[1]}')
```

## Variables casi constantes

```{python}
X_train, X_test, y_train, y_test = preamble('../data/dataset_1.csv')
```

### Enfoque de frecuencia absoluta

```{python}
quasi_constant_features_FA = [
    feature for feature in X_train.columns
    if  X_train[feature].value_counts(normalize=True).max() > 0.998
]

print(len(quasi_constant_features_FA))
```

### Enfoque de umbral de varianza

```{python}
from sklearn.feature_selection import VarianceThreshold

sel = VarianceThreshold(threshold=0.01)
sel.fit(X_train)
```

```{python}
quasi_constant_features_VT = X_train.columns[~sel.get_support()]
print(len(quasi_constant_features_VT))
print(len(quasi_constant_features_FA) - len(quasi_constant_features_VT))
```

```{python}
X_train = sel.transform(X_train)
X_test = sel.transform(X_test)

print(f'The number of columns in X_train is {X_train.shape[1]}')
```

## Variables duplicadas

```{python}
X_train, X_test, y_train, y_test = preamble('../data/dataset_1.csv')
```

```{python}
from feature_engine.selection import DropConstantFeatures

sel = DropConstantFeatures(tol=1, variables=None, missing_values='raise')

sel.fit(X_train)

print(sel.features_to_drop_)
print(len(sel.features_to_drop_))

X_train = sel.transform(X_train)
X_test = sel.transform(X_test)
```

```{python}
sel = DropConstantFeatures(tol=0.998)

sel.fit(X_train)

print(sel.features_to_drop_)
print(len(sel.features_to_drop_))

X_train = sel.transform(X_train)
X_test = sel.transform(X_test)

X_train.shape, X_test.shape
```

```{python}
from feature_engine.selection import DropDuplicateFeatures

sel = DropDuplicateFeatures()
sel.fit(X_train)

pprint.pprint(sel.duplicated_feature_sets_)

print(sel.features_to_drop_)
print(len(sel.features_to_drop_))

X_train = sel.transform(X_train)
X_test = sel.transform(X_test)

X_train.shape, X_test.shape
```
